# Wallet Analysis System Refactoring Implementation Plan (Revised)

**Status Update (as of current conversation):** Core logic extraction is largely complete for Behavior, Correlation, Similarity, and PNL/Stats analysis. Reporting Service handles report generation. Scripts for `activityCorrelator`, `wallet-behavior-analyzer`, `kpi-comparison-report`, and `helius-analyzer` have been refactored to use the new services. Database schema changes for User/ActivityLog and `DatabaseService` enhancements are also complete.

## Immediate Focus (Next Steps)

1.  **Implement API Authentication Middleware:** Develop middleware for the API layer to validate `X-API-Key` headers using `DatabaseService.validateApiKey()`.
2.  **Develop Core API Endpoints (Read-Only):** Create initial RESTful API endpoints for essential read operations (e.g., `GET /wallets/{walletAddress}/summary`), integrating with existing analysis services.
3.  **Integrate User Activity Logging in API:** Implement calls to `DatabaseService.logActivity()` within API endpoints to record user actions, request parameters, and outcomes.
4.  **Refactor Services for API User Context:** Adapt existing analysis services (`BehaviorService`, `PnlAnalysisService`, etc.) to accept a `userId` or user context, enabling them to use `DatabaseService.logActivity()` when invoked via the API.

## Phase 1: Core Analysis Logic Extraction (Complete for Behavior/Correlation/Similarity)

### 1.1 Reorganize Existing Types (Complete)
Location: `src/types/`
- Types are consolidated in `analysis.ts`, `behavior.ts`, `correlation.ts`, `similarity.ts`, `wallet.ts`, etc.

### 1.2 Extract Core Analysis Logic (Complete for Behavior/Correlation/Similarity)

#### 1.2.1 Correlation Analysis
Location: `src/wallet_analysis/core/correlation/analyzer.ts`
- `CorrelationAnalyzer` class encapsulates pairwise scoring, clustering, and global token stats calculation, migrated from `activityCorrelator.ts`.

#### 1.2.2 Behavior Analysis
Location: `src/wallet_analysis/core/behavior/analyzer.ts`
- `BehaviorAnalyzer` class encapsulates sequence building, metrics calculation, and classification, migrated from `wallet-behavior-analyzer.ts`.

#### 1.2.3 Similarity Analysis
Location: `src/wallet_analysis/core/similarity/analyzer.ts`
- `SimilarityAnalyzer` class encapsulates vector creation (capital/binary) and similarity scoring (cosine), migrated from `walletSimilarity.ts`.

#### 1.2.4 KPI Reporting Analysis
Location: `src/wallet_analysis/core/reporting/kpi_analyzer.ts`
- `KPIComparisonAnalyzer` encapsulates comparative report generation logic from `kpi-comparison-report.ts`.

### 1.3 Extract Utility Functions (Complete)

#### 1.3.1 PNL Calculation
Location: `src/wallet_analysis/utils/pnl_calculator.ts`
- Contains `calculateWalletPnl` and `calculatePnlForWallets`, extracted from `activityCorrelator.ts`.

#### 1.3.2 Reporting Utilities
Location: `src/wallet_analysis/reporting/report_utils.ts`
- Contains `generateBehaviorReport`, `generateCorrelationReport`, `generateSimilarityReport`, and `saveReport`, consolidating logic from multiple scripts.

## Phase 2: Service Layer Enhancement (Complete for Behavior/Correlation/Similarity/Reporting)

### 2.1 Analysis Services
Location: `src/wallet_analysis/services/`

#### 2.1.1 `CorrelationService`
- Uses `CorrelationAnalyzer`.
- Integrates database fetching (via `DatabaseService`).
- Integrates bot filtering logic (from `activityCorrelator.ts`).
- Integrates PNL calculation (using `pnl_calculator.ts`).

#### 2.1.2 `BehaviorService`
- Uses `BehaviorAnalyzer`.
- Integrates database fetching (via `DatabaseService`).

#### 2.1.3 `SimilarityService`
- Uses `SimilarityAnalyzer`.
- Integrates database fetching (via `DatabaseService`).
- Integrates shared token analysis (from `walletSimilarity.ts`).

#### 2.1.4 `ReportingService`
- Uses `BehaviorService`, `CorrelationService` (optional), `SimilarityService` (optional), `KPIComparisonAnalyzer`.
- Uses `report_utils.ts` to generate and save various report types (individual behavior, comparative behavior, correlation, similarity).

### 2.2 Enhance Existing Services (Ongoing)

- `DatabaseService`: Refactored into a class. Imports in older scripts like `helius-analyzer.ts` need updating.
- `HeliusApiClient`: Assumed functional based on plan.
- `HeliusTransactionMapper`: Assumed functional based on plan.

## Phase 3: Script Refactoring (Ongoing)

**Goal:** Transform scripts in `src/scripts/` to act as simple orchestrators or entry points that primarily call the new services.

### 3.1 `activityCorrelator.ts`
- **Status: Complete**
- The script now handles CLI argument parsing (wallet source, excludeMints, timeRange).
- It instantiates `DatabaseService`, `CorrelationService`, and `ReportingService`.
- It creates `CorrelationAnalysisConfig` with CLI args.
- It calls `reportingService.generateAndSaveCorrelationReport` to orchestrate the analysis and reporting.
- Internal logic for fetching, filtering, PNL calculation, analysis, clustering, and report generation has been removed.

### 3.2 `wallet-behavior-analyzer.ts`
- **Status: Complete** 
- The script now handles CLI argument parsing (walletAddress, label, excludeMints, timeRange).
- It instantiates `DatabaseService`, `BehaviorService`, and `ReportingService`.
- It creates `BehaviorAnalysisConfig` with CLI args.
- It calls `behaviorService.analyzeWalletBehavior`.
- It calls `reportingService.generateAndSaveIndividualBehaviorReport`.
- Internal logic for fetching, analysis, and reporting has been removed.

### 3.3 `kpi-comparison-report.ts`
- **Status: Complete** 
- The script now handles CLI argument parsing (walletList file, excludeMints, timeRange).
- It instantiates `DatabaseService`, `BehaviorService`, `KPIComparisonAnalyzer`, and `ReportingService`.
- It creates `BehaviorAnalysisConfig` with CLI args.
- It calls `reportingService.generateComparativeBehaviorReport`.
- Internal logic for fetching, analysis, and reporting has been removed.

### 3.4 `walletSimilarity.ts`
- **Status: To Do**
- **Goal:** Update `main` function to orchestrate service calls.
- **Required Refactoring Steps:**
    - Parse CLI args (wallet source, vector type, potentially timeRange/excludeMints).
    - Instantiate `DatabaseService` and `SimilarityService`.
    - Create `SimilarityAnalysisConfig` (potentially including timeRange/excludeMints).
    - Instantiate `ReportingService` (injecting `SimilarityService`).
    - Call `reportingService.generateAndSaveSimilarityReport(walletAddresses, vectorType)`.
    - Remove internal logic for fetching, shared token analysis, vector creation, similarity calc, and reporting.

### 3.5 `helius-analyzer.ts`
- **Status: Complete**
- **Description:** The script has been refactored to act as an orchestrator, leveraging dedicated services (`HeliusSyncService`, `PnlAnalysisService`, `ReportingService`, `DatabaseService`) for data synchronization, analysis, and reporting, preserving previous functionalities like fetching modes and CSV export.
- **Key Components Used:**
    - `HeliusSyncService`: Manages data fetching, mapping, and storage.
    - `PnlAnalysisService`: Orchestrates P/L and stats calculation.
    - `ReportingService`: Generates and saves Markdown/CSV reports.
    - `DatabaseService`: Used directly by the script for managing `AnalysisRun` records.
    - `cliUtils` / `displayUtils`: For parsing and displaying.
- **Refactoring Steps Taken (Summary):**
    1. Extracted core swap logic to `SwapAnalyzer`.
    2. Extracted core stats logic to `AdvancedStatsAnalyzer`.
    3. Created `HeliusSyncService` for data fetching/syncing.
    4. Created `PnlAnalysisService` for orchestrating analysis.
    5. Updated `ReportingService` and `report_utils.ts` for PNL reports.
    6. Refactored `helius-analyzer.ts` script to use these services and manage `AnalysisRun` persistence.

## Phase 4: API Layer Implementation

**Goal:** Develop a robust API layer to expose analysis functionalities for client applications (e.g., dashboards), enable user tracking, and support scalable architecture. This phase transitions the system from script-driven to service-accessible.

### 4.1 API Design Principles & Technology

#### 4.1.1 Foundational Principles
- **RESTful Architecture:** Adhere to REST principles for resource naming, HTTP methods, and status codes.
- **Statelessness:** API endpoints will be stateless where possible, not relying on server-side session memory between requests.
- **Versioning:** API endpoints will be versioned (e.g., `/api/v1/...`) to allow for future iterations without breaking existing clients.
- **Consistent Error Handling:** Implement a standardized error response format.
- **Authentication:** Secure endpoints using API key-based authentication.

#### 4.1.2 API Technology Stack & Framework Selection
- **Context:** The backend is TypeScript-based, utilizing Prisma. The API layer should integrate seamlessly.
- **Recommendation:** A Node.js framework is highly recommended.
    - **NestJS:** An opinionated, TypeScript-first framework promoting robust architectural patterns (modules, services, controllers) that align well with the existing service-oriented structure. Provides strong out-of-the-box support for OpenAPI (Swagger) generation, validation, and more.

#### 4.1.3 API Documentation (OpenAPI/Swagger)
- **Requirement:** Implement automated generation of OpenAPI (Swagger) documentation from the outset. 
- **Benefits:** Provides a live, accurate API reference crucial for dashboard developers, simplifies development, testing, and future maintenance.
- **Implementation:** 
    - If NestJS is chosen, it has excellent built-in support.
    - For Fastify, libraries like `fastify-swagger` can be integrated.

- **Auto-generating client SDKs from routes**

#### 4.1.4 Configuration Management (API & Keys)
- **API Keys:**
    - Generation: Securely generate API keys for `User` models.
    - Storage: Store API keys hashed in the database (e.g., using `bcrypt`). The actual key is shown to the user once upon creation.
- **Application Configuration:**
    - Manage API application settings (database connection strings, logging levels, JWT secrets if used later) via environment variables (e.g., using a `.env` file with `dotenv` library), consistent with Prisma's `DATABASE_URL` handling.

### 4.2 Core API Components & User Tracking

#### 4.2.1 Database Schema for User Tracking (to be added to `prisma/schema.prisma`)
Two new models will be introduced:

```prisma
// In prisma/schema.prisma

model User {
  id           String    @id @default(cuid()) // Or use autoincrement Int
  apiKey       String    @unique // For API authentication
  description  String?   // e.g., "Dashboard Primary Access", "Analyst X"
  createdAt    DateTime  @default(now())
  lastSeenAt   DateTime?
  isActive     Boolean   @default(true)
  activityLogs ActivityLog[]
  // Optional: Link to user-specific settings or saved wallet lists
}

model ActivityLog {
  id                 String    @id @default(cuid()) // Or use autoincrement Int
  userId             String
  user               User      @relation(fields: [userId], references: [id])
  actionType         String    // e.g., 'get_wallet_summary', 'get_token_performance', 'run_pnl_analysis'
  timestamp          DateTime  @default(now())
  requestParameters  Json?     // Input parameters for the action
  status             String    // 'SUCCESS', 'FAILURE', 'INITIATED'
  durationMs         Int?      // Duration of the action
  errorMessage       String?
  sourceIp           String?   // Optional: for additional context

  @@index([userId])
  @@index([actionType])
  @@index([timestamp])
}
```

#### 4.2.2 Authentication
- Clients will include an `X-API-Key` header in requests.
- A middleware in the API framework will validate the API key against the `User` table and identify the `userId`.

#### 4.2.3 `DatabaseService` Enhancements (`src/services/database-service.ts`)
The existing `DatabaseService` will be augmented with methods to:
- Create and validate users/API keys.
- Record entries in the `ActivityLog` table (start, success, failure of actions).
- Update `lastSeenAt` for users.

### 4.3 API Endpoints (Illustrative)
All endpoints will be under a base path like `/api/v1/`.

#### 4.3.1 Wallet & General Information Endpoints
-   **`GET /wallets/{walletAddress}/summary`**:
    *   **Purpose:** Provides data for the "Sticky Summary Bar" and "General ACC Info".
    *   **Data:** Wallet address, (future: name/socials if added to `Wallet` model), last active timestamp, days active (derived), key account-level metrics (e.g., latest realized PnL, win rate from `AdvancedStatsResult`), behavior classification (from `BehaviorService`).
    *   **Services Used:** `DatabaseService` (for `AdvancedStatsResult`, `AnalysisResult`), `BehaviorService`.
    *   **Data Derivation Notes for "Last Active" and "Days Active":**
        *   **Wallet's "Last Active Timestamp":** Determine based on the more recent of `Wallet.newestProcessedTimestamp`.
        *   **Wallet's "Days Active":** This refers to unique days with on-chain activity. This may require pre-calculation by a service (e.g., `PnlAnalysisService` or a new `WalletStatsService`) and stored or efficiently queried. Avoid complex on-the-fly calculations in the API for this metric if performance is critical. - check if other services are not doing this already
-   **`GET /wallets/{walletAddress}/info`**: (Potentially merged into summary or separate for more static details)
    *   **Purpose:** Basic wallet identification details.
    *   **Data:** Wallet address, (future: user-defined name, linked social media accounts - requires `Wallet` model extension or a `WalletMetadata` table).
    *   **Services Used:** `DatabaseService`.

#### 4.3.2 Token Performance View Endpoints
-   **`GET /wallets/{walletAddress}/runs/latest/token-performance`**:
    *   **Purpose:** Powers the "aggregated data on token level" view.
    *   **Data:** Paginated and sortable list of token performance records from the latest `AnalysisResult` for the given wallet. Includes fields like `tokenAddress`, `netAmountChange`, `netSolProfitLoss`, etc.
    *   **Query Params:** `page`, `pageSize`, `sortBy`, `sortOrder`.
    *   **Services Used:** `DatabaseService`.
-   **`GET /wallets/{walletAddress}/runs/{runId}/token-performance`**: Same as above, but for a specific `runId`.

#### 4.3.3 Aggregated Metrics View Endpoints
-   **`GET /wallets/{walletAddress}/runs/latest/aggregated-metrics`**:
    *   **Purpose:** Powers the "aggregated metrics" view.
    *   **Data:** Comprehensive metrics from the latest `AdvancedStatsResult` (median PnL, win rate, etc.) and potentially other overall statistics derived from `AnalysisResult` not covered in `AdvancedStatsResult`.
    *   **Services Used:** `DatabaseService` (to fetch `AdvancedStatsResult`).
-   **`GET /wallets/{walletAddress}/runs/{runId}/aggregated-metrics`**: Same as above, for a specific `runId`.

#### 4.3.4 Behavior View Endpoints
-   **`GET /wallets/{walletAddress}/runs/latest/behavior-analysis`**:
    *   **Purpose:** Powers the "behavior" view.
    *   **Data:** Structured output from `BehaviorService` including trader classification, pattern timelines, consistency metrics, efficiency scores, strategic tags, temporal behavior details. This will be more granular than the summary classification.
    *   **Services Used:** `BehaviorService`.
-   **`GET /wallets/{walletAddress}/runs/{runId}/behavior-analysis`**: Same as above, for a specific `runId`.

#### 4.3.5 Analysis Triggering Endpoints (Optional - for future dashboard control)
-   **`POST /analyses/wallets/{walletAddress}/pnl`**:
    *   **Purpose:** Allow the dashboard to initiate a new PNL & Stats analysis for a wallet.
    *   **Request Body:** Configuration options (e.g., time range, specific parameters for `PnlAnalysisService`).
    *   **Response:** Analysis run ID and status (e.g., `initiated`).
    *   **Services Used:** `PnlAnalysisService`, `DatabaseService` (to create `AnalysisRun` record).
-   **`POST /analyses/wallets/{walletAddress}/behavior`**:
    *   **Purpose:** Initiate a new behavior analysis.
    *   **Request Body:** Configuration options for `BehaviorService`.
    *   **Services Used:** `BehaviorService`, `DatabaseService`.
    *(Similar endpoints can be added for `CorrelationService` and `SimilarityService` if needed).*

### 4.4 Service Layer Interaction
- API controllers/handlers (e.g., in `src/api/controllers/`) will:
    1. Perform request validation and parse parameters.
    2. Authenticate the request via API key, retrieve `userId`.
    3. Call `databaseService.logActivityStart(userId, actionType, params)`.
    4. Instantiate and invoke the appropriate service(s) from:
        - `src/wallet_analysis/services/BehaviorService.ts`
        - `src/wallet_analysis/services/CorrelationService.ts`
        - `src/wallet_analysis/services/SimilarityService.ts`
        - `src/wallet_analysis/services/ReportingService.ts` (for complex report structures if simpler data endpoints are insufficient)
        - `src/wallet_analysis/services/pnl-analysis-service.ts`
        - `src/wallet_analysis/services/helius-sync-service.ts` (if API needs to trigger syncs)
        - `src/wallet_analysis/services/database-service.ts` (for direct data fetching and user/activity logging).
    5. Services will be refactored if necessary to accept `userId` or a user context object for logging and potential future authorization logic.
    6. Format service responses for the API.
    7. Call `databaseService.logActivityEnd(logId, status, duration, errorMessage)`.

### 4.5 Pre-computation vs. On-the-fly API Calculation
- The API will primarily serve pre-calculated data stored by the analysis scripts/services (e.g., `AnalysisResult`, `AdvancedStatsResult`).
- Minor data transformations, filtering, or combining results from different service calls can occur in the API layer or services.
- Computationally intensive analysis will continue to be handled by the core analyzers and services, with results persisted to the database. The API can trigger these processes if `Analysis Triggering Endpoints` are implemented.

### 4.6 Relationship with Existing Scripts
- **Coexistence:** Existing scripts (e.g., `activityCorrelator.ts`, `helius-analyzer.ts`) can continue to operate for batch processing, scheduled tasks, or direct CLI use.
- **API for On-Demand:** The API layer primarily serves interactive, on-demand requests, typical of a dashboard interface.
- **Future Evolution:** Some script functionalities might eventually be triggerable via the API or refactored to use API endpoints for consistency, but this is not an immediate priority. The focus is on exposing read-heavy data and core analysis results via the API first.

## Phase 5: Dashboard Integration Strategy

**Goal:** Develop a web-based dashboard that consumes the API layer to provide users with insights into wallet analysis data.

### 5.1 Dashboard Development Approach Recommendation
1.  **API Layer First (Phase 4):** Complete the implementation of core read-only API endpoints (wallet summary, token performance, aggregated metrics, behavior details) along with authentication and basic activity logging. This establishes a stable contract.
2.  **Dashboard Skeleton & Core View (Iterative):**
    *   **UI/UX Prototyping:** Develop basic wireframes/mockups for all planned dashboard views if not already detailed enough.
    *   **Framework Setup:**: Integrate component-based dashboard builders like [React-Admin], [Tremor], [Chakra UI], or [ShadCN + Recharts] to cut UI time.

    *   **Layout Implementation:** Build the main dashboard layout: Sidebar, Main Window, Sticky Summary Bar, and the tabbed/collapsible structure for the bottom data views.
    *   **Connect Core View:** Implement the "Sticky Summary Bar" by fetching data from `GET /wallets/{walletAddress}/summary`. Then, connect one of the primary data views (e.g., "Token Performance") to its respective API endpoint.
3.  **Iterative Development of Dashboard Views & API Refinement:**
    *   Implement the remaining dashboard views one by one (Aggregated Metrics, Behavior), connecting them to their API endpoints.
    *   As dashboard development progresses, identify any new data requirements, filtering needs, or sorting capabilities. Refine or add API endpoints accordingly. This is an iterative loop between frontend needs and backend capabilities.
4.  **Implement Analysis Triggering (Optional):** If the dashboard requires users to initiate new analyses, develop the UI for this and connect it to the "Analysis Triggering Endpoints" defined in Phase 4.3.5.
5.  **User Management UI (Future):** If admins need to manage users and API keys via the dashboard, a separate section and corresponding API endpoints would be required.

### 5.2 Dashboard Structure Mapping (based on user diagram)
-   **Sidebar:** Navigation for wallet selection (may require `GET /api/v1/users/{userId}/wallets` or similar endpoint in the future, or client-side management initially), settings, help.
-   **Main Window - Sticky Summary Bar (Top):**
    *   Displays data from `GET /wallets/{walletAddress}/summary`.
    *   Includes: Wallet Address, Last Active, Days Active, Top 3 Account-Level Metrics, Behavior Profile/Category.
-   **Main Window - Bottom Section (Tabs/Collapsible Views):**
    *   **View 1: Token Performance:** Consumes `GET .../token-performance`. Displays sortable, paginated list of per-token PNL and metrics.
    *   **View 2: Aggregated Metrics:** Consumes `GET .../aggregated-metrics`. Displays overall PNL, win rates, averages, trading frequency from `AdvancedStatsResult`.
    *   **View 3: Behavior Details:** Consumes `GET .../behavior-analysis`. Shows detailed trader classification, pattern timelines, consistency metrics, efficiency scores, etc.

## Phase 6: AI Assistant Integration (Experimental Pilot)

**Goal:** Explore and validate the value of an LLM-based AI assistant for natural language querying of analysis data and generating summaries, leveraging the established API layer.

**Trigger:** Core API endpoints are stable and initial dashboard views are functional, providing a clear understanding of available data and user interaction patterns.

**Prerequisites:**
- Stable API Layer (Phase 4 completed for core read endpoints).
- Well-defined data models and metrics (from Phases 1-3 and `prisma/schema.prisma`).
- Initial Dashboard implementation (Phase 5.1 and 5.2 underway) to inform valuable AI use cases.

**Recommended Timing:** Commence exploration during or after initial dashboard milestones (e.g., after Phase 5.2, when key dashboard views are connected to the API).

**Approach & Smart Choices:**
- **Tool-Based LLM Interaction:** Utilize a structured approach for LLM interaction, such as Anthropic's model context protocol or similar frameworks that allow defining tools for the LLM.
- **API as the Primary Tool Source:** Design LLM tools primarily as wrappers around the existing, validated API endpoints (developed in Phase 4).
    - *Example:* An LLM tool `getWalletPNLSummary(wallet_address: string)` would internally call the `GET /wallets/{walletAddress}/summary` API endpoint.
- **Focus on Read-Only Operations Initially:** Prioritize use cases like natural language querying and data summarization. Defer AI-driven actions (e.g., triggering new analyses) until read capabilities are mature and robust.
- **Isolate AI Components:** Develop AI integration as a distinct module or service to allow for independent iteration and experimentation without destabilizing core application logic or the primary dashboard.
- **Iterative Development & Prompt Engineering:** Treat as an experimental feature. Expect an iterative process of refining prompts, tools, and handling LLM responses.

**Potential Initial Use Cases:**
- Natural language queries for specific metrics: "What was wallet X's win rate last month?" or "Show me the PNL for SOL for wallet Y."
- Automated summaries of wallet behavior or performance based on available API data.
- Conversational exploration of data presented in the dashboard.

**Considerations for Technical Debt & Overhead:**
- **Avoid Direct Database Access by LLM:** Enforce LLM interaction via the API to maintain security, abstraction, and maintainability.
- **Start Small & Focused:** Begin with a few high-impact, low-complexity use cases to demonstrate value and refine the integration approach.
- **Human-in-the-Loop (HITL):** For complex queries or sensitive data synthesis, consider HITL mechanisms initially to validate AI outputs.

## Phase 7: Performance & Asynchronous Operations (Future Enhancement)

**Trigger:** API endpoints for triggering new analyses (see 4.3.5) become slow or block client requests for too long; need to process multiple analysis requests concurrently without overwhelming system resources.

**Smart Choices (aligned with `docs/scaling.md` Phase 2):

### 7.1 Job Queue System Introduction
- **Technology:** Introduce a job queue system (e.g., BullMQ) with Redis as the broker.
- **Purpose:** Offload long-running analysis tasks (PNL, Behavior, Correlation, Similarity) initiated via API calls to background workers.

### 7.2 API Integration with Job Queue
- API endpoints that trigger analyses (e.g., `POST /analyses/wallets/{walletAddress}/pnl`) will now:
    1. Validate the request and parameters.
    2. Add a job to the appropriate queue (e.g., `pnl-analysis-queue`).
    3. Return an immediate response (e.g., `202 Accepted` with a job ID).
- New API endpoints might be needed to check the status of a job (`GET /analyses/jobs/{jobId}`).

### 7.3 Worker Services Implementation
- Develop separate Node.js worker processes for each type of analysis or a generic worker that can handle different job types.
- Workers will listen to their respective queues.
- Upon receiving a job, a worker will:
    1. Instantiate and use the relevant services (`PnlAnalysisService`, `BehaviorService`, etc.) to perform the analysis.
    2. Update the job status in the queue and potentially in the `AnalysisRun` table in the database.
    3. Handle errors gracefully and update job status accordingly.

### 7.4 Benefits
- **Non-blocking API:** Improves API responsiveness for analysis-triggering requests.
- **Scalability:** Worker processes can be scaled independently based on load.
- **Resilience:** Jobs can be retried if workers fail (if queue is configured for retries).

## Phase 8: Advanced Database Scalability & Optimization (Future Enhancement)

**Trigger:** SQLite performance degrades significantly with a very large volume of transactions across many wallets; write contention becomes an issue; complex analytical queries for the dashboard become too slow despite optimizations.

**Smart Choices (aligned with `docs/scaling.md` Phase 4):

### 8.1 Database Migration to PostgreSQL
- **Action:** Use Prisma's migration capabilities to transition the database from SQLite to PostgreSQL.
- **Benefits:** PostgreSQL offers superior concurrency, scalability, robustness, and advanced features suitable for larger datasets and higher transaction volumes.
- **Impact:** Application code using Prisma Client will remain largely unchanged, demonstrating the power of the ORM.

### 8.2 Advanced Caching Layer
- **Technology:** Expand the use of Redis (introduced with job queues) or a similar caching solution.
- **Strategy:** Implement caching for frequently accessed, computationally expensive, or relatively static data:
    - Wallet summaries or frequently requested aggregated metrics from the API.
    - Results of common queries to `DatabaseService`.
- **Invalidation:** Develop a clear cache invalidation strategy to ensure data consistency.

### 8.3 Analytical Acceleration (If Required for Complex Dashboarding)
- **Context:** If dashboard queries remain slow even with PostgreSQL and caching, for highly complex, read-heavy analytics.
- **Options:**
    - **DuckDB:** For local or embedded analytics, potentially querying Parquet exports or a read replica of PostgreSQL.
    - **ETL + Data Warehouse (for very large scale):** Implement an ETL process to move data from PostgreSQL to a specialized analytical store (e.g., ClickHouse, BigQuery) if the application evolves into a large multi-user service requiring extensive BI capabilities. This is a significant architectural step and considered far-future.

## Implementation Order (Updated)

1.  Type Consolidation (Done)
2.  Core Analysis Extraction (Done)
3.  Utility Function Extraction (Done)
4.  Service Implementation (Refinement for user context may be needed) (Largely Done)
5.  Configuration Type Refactoring (Done)
6.  Script Transformation (Done)
    - `activityCorrelator.ts` (Done)
    - `wallet-behavior-analyzer.ts` (Done)
    - `kpi-comparison-report.ts` (Done)
    - `helius-analyzer.ts` (Done)
    - `walletSimilarity.ts` (Done)
7.  **Phase 4: API Layer Implementation (Current Focus)**
    *   7.1 Database schema changes for Users & ActivityLog.
    *   7.2 `DatabaseService` enhancements for user/activity management.
    *   7.3 API endpoint development (authentication, core read endpoints first, tech stack decision).
    *   7.4 Service modifications to accept user context for logging.
8.  **Phase 5: Dashboard Integration (Next Major Phase)**
    *   8.1 Dashboard skeleton and connection to summary API.
    *   8.2 Iterative implementation of dashboard views.
    *   8.3 (Optional) Implementation of analysis triggering from dashboard.
9.  **Testing (Ongoing - See updated Testing Strategy)**
10. **Phase 6: AI Assistant Integration (Experimental Pilot - NEW)**
    *   10.1 Define initial scope & use cases (e.g., natural language query for wallet summary).
    *   10.2 Design LLM tools based on existing API endpoints.
    *   10.3 Develop and test a pilot integration.
11. **Phase 7: Performance & Asynchronous Operations (Future Enhancement - formerly Phase 6)**
    *   11.1 Implement Job Queue System (e.g., BullMQ + Redis).
    *   11.2 Refactor API analysis triggers to use the job queue.
    *   11.3 Develop Worker Services.
12. **Phase 8: Advanced Database Scalability & Optimization (Future Enhancement - formerly Phase 7)**
    *   12.1 Migrate to PostgreSQL if SQLite limits are hit.
    *   12.2 Implement/Expand Caching Layer (Redis).
    *   12.3 Consider analytical acceleration tools if dashboarding complexity demands it.
13. (Further Future API Layer for Admin/Advanced Features)

## Testing Strategy (Updated)
